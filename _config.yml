# Site
repository: https://github.com/Soroosh-Bsl/soroosh-bsl.github.io
# favicon: Directory of your favicon (eg. images/favicon.ico)(optional)

# Content configuration version
version: 2

# Personal info
name: Soroosh Baselizadeh
# title: Your job title
email: sbaseliz@gmail.com
# email_title: Email (Email title override)
# phone: Your phone number (optional)
# phone_title: Phone (Phone title override)
# website: Your website (eg. https://google.com)(optional)
# website_title: Web (Website title override)

# Dark Mode (true/false/never)
darkmode: false

# Social links
# twitter_username: jekyllrb
github_username:  soroosh-bsl
#stackoverflow_username: "00000001"
#dribbble_username: jekyll
#facebook_username: jekyll
#flickr_username: jekyll
#instagram_username: jekyll
linkedin_username: soroosh-baselizadeh
#xing_username: jekyll
#pinterest_username: jekyll
#youtube_username: jekyll
#googleplus_username: +jekyll
#orcid_username: 0000-0000-0000-0000
semantic_scholar_username: Soroosh-Baselizadeh+1429835055
google_scholar_username: DHb2F-0AAAAJ

# Additional icon links
#additional_links:
# - title: My SemanticScholar
#  icon: ai ai-semantic-scholar ai-4x
#  url: https://www.semanticscholar.org/author/Soroosh-Baselizadeh/1429835055
# - title: another link
#   icon: font awesome brand icon name (eg. fab fa-twitter) (https://fontawesome.com/icons?d=gallery&s=brands&m=free)
#   url: Link url (eg. https://google.com)

# Google Analytics and Tag Manager
# Using more than one of these may cause issues with reporting
# gtm: "GTM-0000000"
# gtag: "UA-00000000-0"
# google_analytics: "UA-00000000-0"
#<a href='https://www.freepik.com/vectors/background'>Background vector created by freepik - www.freepik.com</a>
# About Section
# about_title: About Me (Use this to override about section title)
about_profile_image: /images/profile.jpg
about_content: | # this will include new lines to allow paragraphs

  I am a Machine Learning Researcher and Engineer at Electronic Arts Inc., Canada, specializing in computer vision and advanced ML applications. I earned my B.Sc. in Computer Engineering from Sharif University of Technology, where I worked with Prof. <a href="https://scholar.google.com/citations?hl=en&user=pRyJ6FkAAAAJ&view_op=list_works">M.H. Rohban</a>. I completed my M.Sc. in Computer Science from the University of Waterloo under Profs. <a href="https://scholar.google.com/citations?hl=en&user=h6_PdYsAAAAJ">Yuri Boykov</a> and <a href="https://scholar.google.com/citations?hl=en&user=r5QkMysAAAAJ">Olga Veksler</a>. Previously, I collaborated with Prof. <a href="https://scholar.google.de/citations?hl=en&user=kzoVUPYAAAAJ&view_op=list_works">Nassir Navab</a> at the CAMP lab, Technical University of Munich. My research focuses on segmentation, anomaly detection, explainable AI, and knowledge distillation, with contributions published in top venues like CVPR, AAAI, MICCAI, and ICML, where I have also served as a reviewer.
content:
  - title: Education
    layout: list
    content:
      - layout: left
        title: University of Waterloo
        sub_title: Master's in Computer Science
        caption: Sep. 2021 - Sep. 2023
        description: |
            <b>Supervisors</b>: <a href="https://scholar.google.com/citations?hl=en&user=h6_PdYsAAAAJ&view_op=list_works&sortby=pubdate">Prof. Yuri Boykov</a> 
            and <a href="https://scholar.google.com/citations?hl=en&user=r5QkMysAAAAJ&view_op=list_works&sortby=pubdate">Prof. Olga Veksler</a>
            <br><b>Related Coursework</b>: Deep Learning, Computational Vision, Reinforcement Learning
            <br><b>Thesis</b>: Occlusion-ordered Semantic Instance Segmentation
      - layout: left
        title: Sharif University of Technology
        sub_title: BSc in Computer Engineeiring
        caption: Sep. 2016 - Feb. 2021
        #quote: >
        #  <mark>Ranked 3rd/~110, GPA: 19.45/20</mark>
        description: | # this will include new lines to allow paragraphs          
          <b>Supervisor</b>: <a href="https://scholar.google.com/citations?hl=en&user=pRyJ6FkAAAAJ&view_op=list_works&sortby=pubdate">Prof. MH Rohban</a>
          <br><b>Related Coursework</b>: Probability & Statistics, Linear Algebra, Artificial Intelligence, Signals & Systems, Modern Information Retrieval, Algorithmic Game Theory, Numerical Methods, Design of Algorithms, Computer Simulation, Database Design, Data Structures & Algorithms
  - title: Publications # Title for the section
    layout: list # Type of content section (list/text)
    content:
      - layout: top
        title: Neural Response Interpretation through the Lens of Critical Pathways
        #link: https://arxiv.org/abs/2103.16886
        #link_text: arXiv 
        image: /images/pathway.jpg
        additional_links:
          - title:  Pathway-Grad Code
            icon: fab fa-github
            url: https://github.com/CAMP-eXplain-AI/PathwayGrad
          - title:  ROAR-PyTorch Code
            icon: fab fa-github
            url: https://github.com/CAMP-eXplain-AI/RoarTorch
        #quote: >
        #  Short overview of the project (optional)
        description: | # this will include new lines to allow paragraphs
          Is critical input information encoded in specific sparse pathways within the neural network? In this work, we discuss the problem of identifying these critical pathways and subsequently 
          leverage them for interpreting the network's response to an input. We demonstrate that sparse pathways derived from pruning do not necessarily encode critical input information. <span id="dots_1">...</span><span id="more_1" style="display:none">The pruning objective -- selecting the smallest group of neurons for which the response remains equivalent to the 
          original network -- has been previously proposed for identifying critical pathways. As stated, using pruning objective is flawed for obtaining pathways encoding critical input information.
          To ensure sparse pathways include critical fragments of the encoded input information, we propose pathway selection via neurons' contribution to the response. We proceed to explain how critical pathways can 
          reveal critical input features. We prove that pathways selected via neuron contribution are locally linear (in an L2-ball), a property that we use for 
          proposing a feature attribution method: "pathway gradient". We validate our interpretation method using mainstream evaluation experiments. The validation of pathway gradient interpretation method further confirms 
          that selected pathways using neuron contributions correspond to critical input features.</span>
          <button onclick="moreFunction('dots_1', 'more_1', 'moreBtn_1')" id="moreBtn_1" style="background-color: transparent; border: none; color: black; text-align: center; text-decoration: none; display: inline-block;"><strong>More</strong></button>
          
          <span style="color:#006400"> Ashkan Khakzar, <strong>Soroosh Baselizadeh</strong>, Saurabh Khanduja, Christian Rupprecht, Seong Tae Kim, and Nassir Navab </span>
          
          <span style="color:#000099"> IEEE/CVF Conference on Computer Vision and Pattern Recognition (<mark>CVPR</mark>) 2021
          [<a href="https://arxiv.org/abs/2103.16886">arXiv</a>][<a href="https://openaccess.thecvf.com/content/CVPR2021/html/Khakzar_Neural_Response_Interpretation_Through_the_Lens_of_Critical_Pathways_CVPR_2021_paper.html">CVF OpenAccess</a>]</span>
      - layout: top 
        title: Multiresolution Knowledge Distillation for Anomaly Detection
        image: /images/ad_kd.jpg
        additional_links:
          - title:  AD_KD Code
            icon: fab fa-github
            url: https://github.com/rohban-lab/Knowledge_Distillation_AD
        #quote: >
        #  Short overview of the project (optional)
        description: | # this will include new lines to allow paragraphs
          Here, we propose to use the “distillation” of features at various layers of an expert network, which is pre-trained on ImageNet, into a simpler cloner network to tackle issues in
          unsupervised representation learning for anomaly detection/localization. 
          We detect and localize anomalies using the discrepancy between the expert and cloner networks’ intermediate activation values given an input sample. <span id="dots_2">...</span><span id="more_2" style="display:none">
          Unsupervised representation learning has proved to be a critical component of anomaly detection/localization in images. 
          The challenges to learn such a representation are two-fold. Firstly, the sample size is not often large enough to learn a rich generalizable representation through 
          conventional techniques. Secondly, while only normal samples are available at training, the learned features should be discriminative of normal and anomalous samples. 
          Here, we propose to use the “distillation” of features at various layers of an expert network, which is pre-trained on ImageNet, into a simpler cloner network to tackle both issues. 
          We detect and localize anomalies using the discrepancy between the expert and cloner networks’ intermediate activation values given an input sample. 
          We show that considering multiple intermediate hints in distillation leads to better exploitation of the expert’s knowledge and a more distinctive discrepancy between the two networks, 
          compared to utilizing only the last layer activation values. Notably, previous methods either fail in precise anomaly localization or need expensive region-based training. In contrast, 
          with no need for any special or intensive training procedure, we incorporate interpretability algorithms in our novel framework to localize anomalous regions. 
          Despite the striking difference between some test datasets and ImageNet, we achieve competitive or significantly superior results compared to SOTA on MNIST, F-MNIST, CIFAR-10, MVTecAD, Retinal-OCT, 
          and two other medical datasets on both anomaly detection and localization.</span> 
          <button onclick="moreFunction('dots_2', 'more_2', 'moreBtn_2')" id="moreBtn_2" style="background-color: transparent; border: none; color: black; text-align: center; text-decoration: none; display: inline-block;"><strong>More</strong></button>
          
          <span style="color:#006400"> MohammadReza Salehi, Niousha Sadjadi*, <strong>Soroosh Baselizadeh*</strong>, M. H. Rohban, and Hamid R. Rabiee </span>
          
          <span style="color:#000099"> IEEE/CVF Conference on Computer Vision and Pattern Recognition (<mark>CVPR</mark>) 2021
          [<a href="https://arxiv.org/abs/2011.11108">arXiv</a>][<a href="https://openaccess.thecvf.com/content/CVPR2021/html/Salehi_Multiresolution_Knowledge_Distillation_for_Anomaly_Detection_CVPR_2021_paper.html">CVF OpenAccess</a>]</span>
      
      - layout: top 
        title: Towards Semantic Interpretation of Thoracic Disease and COVID-19 Diagnosis Models
        additional_links:
          - title:  Covid_Interpretation Code
            icon: fab fa-github
            url: https://github.com/CAMP-eXplain-AI/CheXplain-Dissection
        image: /images/covid.jpg 
        description: |
          The black-box nature of CNNs has sparked many recent works to explain the prediction via 
          input feature attribution methods. However, input these methods merely identify the importance of input regions for the prediction and lack semantic interpretation 
          of model behavior. Here, we first identify the semantics associated with internal units (feature maps) of the network. We proceed to investigate the following questions; <span id="dots_3">...</span><span id="more_3" style="display:none">Does a regression model 
          that is only trained with COVID-19 severity scores implicitly learn visual patterns associated with thoracic pathologies? 
          Does a network that is trained on weakly labeled data (e.g. healthy, unhealthy) 
          implicitly learn pathologies? Moreover, we investigate the effect of pretraining and data imbalance on the interpretability of learned features. 
          In addition to the analysis, we propose semantic attribution to semantically explain each prediction. 
          We present our findings using publicly available chest pathologies (CheXpert, NIH ChestX-ray8) 
          and COVID-19 datasets (BrixIA, and COVID-19 chest X-ray segmentation dataset).</span>
          <button onclick="moreFunction('dots_3', 'more_3', 'moreBtn_3')" id="moreBtn_3" style="background-color: transparent; border: none; color: black; text-align: center; text-decoration: none; display: inline-block;"><strong>More</strong></button>
                    
          <span style="color:#006400"> A. Khakzar, S. Musatian, J. Buchberger, I. Valeriano Quiroz, N. Pinger, <strong>S. Baselizadeh</strong>, S. T. Kim, Nassir Navab </span>
          
          <span style="color:#000099"> International Conference on Medical Image Computing and Computer-Assisted Intervention (<mark>MICCAI</mark>) 2021
          [<a href="https://arxiv.org/abs/2104.02481">arXiv</a>]
          [<a href="https://link.springer.com/chapter/10.1007%2F978-3-030-87199-4_47">Springer (DOI)</a>]
          [<a href="https://rdcu.be/cyl4H">SharedIt</a>]</span>         
      
      - layout: top 
        title: Rethinking Positive Aggregation and Propagation of Gradients in Gradient-based Saliency Methods
        image: /images/rethink.jpg
        #quote: >
        #  Short overview of the project (optional)
        description: | # this will include new lines to allow paragraphs
          A popular family of saliency methods utilize gradient information. 
          In this work, we empirically show that two approaches for handling the gradient information, namely positive aggregation, and positive propagation, 
          (e.g. in methods like GradCAM++ and FullGrad)
          break these methods. Though these methods reflect visually salient information in the input, they do not explain the model prediction 
          anymore <span id="dots_4">...</span><span id="more_4" style="display:none">as the generated saliency maps are insensitive to the predicted output and are insensitive to model parameter 
          randomization. Specifically for methods that aggregate the gradients of a chosen layer such as GradCAM++ and FullGrad, exclusively aggregating positive gradients is detrimental. 
          We further support this by proposing several variants of aggregation methods with positive handling of gradient information. 
          For methods that backpropagate gradient information such as LRP, RectGrad, and Guided Backpropagation, we show the destructive effect of 
          exclusively propagating positive gradient information.</span>
          <button onclick="moreFunction('dots_4', 'more_4', 'moreBtn_4')" id="moreBtn_4" style="background-color: transparent; border: none; color: black; text-align: center; text-decoration: none; display: inline-block;"><strong>More</strong></button>
          
          <span style="color:#006400"> Ashkan Khakzar, <strong>Soroosh Baselizadeh</strong>, Nassir Navab </span>
          
          <span style="color:#000099"> International Conference on Machine Learning (<mark>ICML</mark>) 2020 - Workshop on Human Interpretability in ML (<mark>WHI</mark>)
          [<a href="https://arxiv.org/abs/2012.00362">arXiv</a>][<a href="https://drive.google.com/file/d/1lKd1bciGkeh1y6fjwJlUpToD1eJyzap5/view?usp=sharing">Full Proceedings of the Venue</a>]</span>
          
          
      #- layout: left 
      #  title: Improving Feature Attribution through Input-specific Network Pruning
      #  image: /images/pruning.jpg 
      #  description: |
      #    Attributing the output of a neural network to the contribution of given input elements is a way of shedding light on the black-box nature of neural networks. Due to the complexity of current network architectures, current gradient-based attribution methods provide very noisy or coarse results. We propose to prune a neural network for a given single input to keep only neurons that highly contribute to the prediction. We show that by input-specific pruning, network gradients change from reflecting local (noisy) importance information to global importance. Our proposed method is efficient and generates fine-grained attribution maps. We further provide a theoretical justification of the pruning approach relating it to perturbations and validate it through a novel experimental setup. Our method is evaluated by multiple benchmarks: sanity checks, pixel perturbation, and Remove-and-Retrain (ROAR). These benchmarks evaluate the method from different perspectives and our method performs better than other methods across all evaluations.
          
      #    <span style="color:#006400"> Ashkan Khakar, <strong>Soroosh Baselizadeh</strong>, Saurabh Khanduja, Christian Rupprecht, Seong Tae Kim, and Nassir Navab </span>
      #    <span style="color:#000099">[<a href="https://arxiv.org/abs/1911.11081">arXiv</a>]</span>
  - title: Experiences
    layout: list
    content:
      - layout: left
        title: Machine Learning Researcher and Engineer
        sub_title: Electronic Arts (EA)
        caption: Sep. 2021 - Present
        quote: >
          Advanced Technology Group (ATG) @ EA Sports, Vancouver, Canada
        description: | # this will include new lines to allow paragraphs
            + Working on novel computer vision and ML solutions to enhance gaming experiences across EA Sports titles.
          
      - layout: left
        title: Remote Research Assistant
        sub_title: CAMP @ TUM, Germany
        caption: July 2019 - March 2021
        link: https://www.cs.cit.tum.de/camp/start/
        quote: >
          Computer Aided Medical Procedueres and Augmented Reality (CAMP) @ Technical University of Munich, Germany
        description: | # this will include new lines to allow paragraphs
          + Collaborated in a multi-organizational and international team from the UK (Oxford) and Germany (TUM)
          + Designed and implemented a new algorithm for explaining deep image classification models using critical pathways in neural networks, improving the state-of-the-art on CIFAR, BirdSnap by 10%
          + Implemented sanity checks methods from scratch using PyTorch, numpy, sklearn, and scipy, including layer-by-layer model randomization and input randomization
          + Formulated the critical pathways in deep models as a linear approximation, proving the efficacy of the method
          + Implemented, and analyzed weaknesses of 5+ gradient-based image saliency methods using PyTorch 
          + Developed parts of a study on interpreting the COVID-19 diagnosis deep models and their features’ semantics 
          + Wrote significant parts of publications at CVPR, ICML, and MICCAI
          + Used Git continuously for version control and coordination
      - layout: left
        title: Research Assistant
        sub_title: Robust and Interpretable ML (RIML) Lab
        caption: March 2019 - March. 2021
        quote: >
          Robust and Interpretable Machine Learning (RIML) Lab @ Sharif University of Technology, Iran
        description: | # this will include new lines to allow paragraphs
          + Developed a new method for image anomaly detection & localization based on knowledge distillation & transfer learning improving the state-of-the-art up to 20% on 7 industrial and medical datasets
          + Implemented several interpretability methods of deep neural networks including Grad-CAM, Integrated Gradients, Vanilla Gradients in PyTorch
          + Designed, and implemented experiments for evaluation/ablation using numpy, PyTorch, and matplotlib 
          + Wrote most parts of a paper published at CVPR
          + Presented findings using Jupyter and Tensorboard in meetings, and performed version control on Git
      - layout: left
        title: NLP Intern
        sub_title: Asr Gooyesh Company
        caption: Sep. 2021 - Jan. 2021
        link: http://asr-gooyesh.com/en/
        quote: >
          Natural Language Processing (NLP) Intern 
        additional_links:
          - title:  Asr-Gooyesh LinkedIn
            icon: fab fa-linkedin
            url: https://www.linkedin.com/company/asr-gooyesh-pardaz-co-/
        description: | # this will include new lines to allow paragraphs
          + Crawled, and scrapped user comments data from Twitter and Persian news websites using Scrappy
          + Cleaned, normalized, and pre-processed the collected text data in Python
          + Performed primary data analysis and visualization using Pandas, and matplotlib
          + Labelled, and partitioned train/test data and created a dataset with near 100k size for offensive vs. non-offensive Persian comments based on the preliminary data analysis
          + Implemented Transformer models based on BERT using Wordpiece tokenizer in PyTorch for offensive vs. non-offensive classification of Persian comments
          + Tested, and benchmarked different versions of the model using PyTorch, Seaborn and matplotlib
          + Documented, and presented the findings in meetings and to the R&D department
  - title: Honors & Awards
    layout: text
    content: | # this will include new lines to allow paragraphs
    
      - Reviewer at CVPR2024, AAAI2025, CVPR2025
    
      - David R. Cheriton Graduate Scholarship, Department of Computer Science, University of Waterloo [2021-2023]
    
      - International Master's Award of Excellence (IMAE), University of Waterloo [2021-2023]
    
      - Undergraduate Excellence Award from the Technical University of Munich, Germany [2019]: given annually
        to <= 5 international students with an excellent background by the chair for Computer Aided Medical Procedures and Augmented Reality (CAMP). 
        
      - Ranked 3rd based on GPA out of all ~110 bachelor students of Computer Enigneering Department @ Sharif University of Technology entered at 2016. 
      
      - Iran's National Elites Foundation (INEF) Fellowship [2016-2021]: Recognized as scientiffic elite.

      - Iran's National University Entrance Exam (Konkur) Top Scorer [2016]: Ranked 12th nationally (2nd in the relevant region) out of more than 180'000 (50'000 in the relevant region) participants.
      


# Footer
footer_show_references: true
# references_title: References on request (Override references text)

# Build settings
# theme: modern-resume-theme (Use this is you are hosting your resume yourself)
# remote_theme: sproogen/modern-resume-theme (Use this if you are hosting your resume on GitHub)

sass:
  sass_dir: _sass
  style: compressed

plugins:
 - jekyll-seo-tag

exclude : [
  "Gemfile",
  "Gemfile.lock",
  "node_modules",
  "vendor/bundle/",
  "vendor/cache/",
  "vendor/gems/",
  "vendor/ruby/",
  "lib/",
  "scripts/",
  "docker-compose.yml",
  ]
