# Site
repository: https://github.com/Soroosh-Bsl/soroosh-bsl.github.io
# favicon: Directory of your favicon (eg. images/favicon.ico)(optional)

# Content configuration version
version: 2

# Personal info
name: Soroosh Baselizadeh
# title: Your job title
email: soroosh.baselizadeh@gmail.com
# email_title: Email (Email title override)
# phone: Your phone number (optional)
# phone_title: Phone (Phone title override)
# website: Your website (eg. https://google.com)(optional)
# website_title: Web (Website title override)

# Dark Mode (true/false/never)
darkmode: false

# Social links
# twitter_username: jekyllrb
github_username:  soroosh-bsl
#stackoverflow_username: "00000001"
#dribbble_username: jekyll
#facebook_username: jekyll
#flickr_username: jekyll
#instagram_username: jekyll
linkedin_username: soroosh-baselizadeh-68591019b
#xing_username: jekyll
#pinterest_username: jekyll
#youtube_username: jekyll
#googleplus_username: +jekyll
#orcid_username: 0000-0000-0000-0000
semantic_scholar_username: Soroosh-Baselizadeh+1429835055
# google_scholar_username: ---

# Additional icon links
#additional_links:
# - title: My SemanticScholar
#  icon: ai ai-semantic-scholar ai-4x
#  url: https://www.semanticscholar.org/author/Soroosh-Baselizadeh/1429835055
# - title: another link
#   icon: font awesome brand icon name (eg. fab fa-twitter) (https://fontawesome.com/icons?d=gallery&s=brands&m=free)
#   url: Link url (eg. https://google.com)

# Google Analytics and Tag Manager
# Using more than one of these may cause issues with reporting
# gtm: "GTM-0000000"
# gtag: "UA-00000000-0"
# google_analytics: "UA-00000000-0"
#<a href='https://www.freepik.com/vectors/background'>Background vector created by freepik - www.freepik.com</a>
# About Section
# about_title: About Me (Use this to override about section title)
about_profile_image: /images/profile.jpg
about_content: | # this will include new lines to allow paragraphs
  I am a computer science researcher, primarily focused in Computer Vision, Machine Learning and Deep Learning. I am currently a Computer Science Master's student at the University of Waterloo, 
  where I am supervised by <a href="https://scholar.google.com/citations?hl=en&user=h6_PdYsAAAAJ&view_op=list_works&sortby=pubdate">Prof. Yuri Boykov</a> and 
  <a href="https://scholar.google.com/citations?hl=en&user=r5QkMysAAAAJ&view_op=list_works&sortby=pubdate">Prof. Olga Veksler</a>. 
  In past, I have worked on Trustworthy ML and ML applications in Computer Vision. Below, you can find a summary of my education, publications, and related experiences. 
  I have had close collaboration with CAMP @ Technical University of Munich 
  (supervised by <a href="https://scholar.google.de/citations?hl=en&user=kzoVUPYAAAAJ&view_op=list_works&sortby=pubdate">Prof. Nassir Navab</a>), 
  where I was an Undergraduate Excellence Awardee and a research intern and published a plenty of papers at top-tier conferences. 
  Besides, during my undergrad studies, I have been a member of Robust and Interpretable ML Lab @ Sharif University of Technology, Tehran, Iran 
  (supervised by <a href="https://scholar.google.com/citations?hl=en&user=pRyJ6FkAAAAJ&view_op=list_works&sortby=pubdate">Prof. MH Rohban</a>), 
  where I also published some of my other works. 

content:
  - title: Education
    layout: list
    content:
      - layout: top-left
        title: University of Waterloo
        sub_title: Master's in Computer Science
        caption: Sep. 2021 - Present
        description: |
            <b>Supervisors</b>: <a href="https://scholar.google.com/citations?hl=en&user=h6_PdYsAAAAJ&view_op=list_works&sortby=pubdate">Prof. Yuri Boykov</a> 
            and <a href="https://scholar.google.com/citations?hl=en&user=r5QkMysAAAAJ&view_op=list_works&sortby=pubdate">Prof. Olga Veksler</a>
      - layout: top-left
        title: Sharif University of Technology
        sub_title: BSc in Computer Engineeiring
        caption: Sep. 2016 - Feb. 2021
        quote: >
          <mark>Ranked 3rd/~110, GPA: 19.45/20</mark>
        description: | # this will include new lines to allow paragraphs          
          <b>Supervisor</b>: <a href="https://scholar.google.com/citations?hl=en&user=pRyJ6FkAAAAJ&view_op=list_works&sortby=pubdate">Prof. MH Rohban</a>
          <br><b>Related Coursework</b>: Probability & Statistics, Linear Algebra, Artificial Intelligence, Signals & Systems, Modern Information Retrieval, Algorithmic Game Theory, Numerical Methods, Design of Algorithms, Computer Simulation, Database Design, Data Structures & Algorithms
      - layout: top-left
        title: Allameh-Helli 1
        sub_title: Secondary School, Diploma in Mathematics and Physics
        caption: 2012 - 2016
        quote: >
          <mark>Ranked 1st, GPA: 19.88/20</mark>
        description: | # this will include new lines to allow paragraphs          
          Affiliated with the <b> National Organization for Development of Exceptional Talents (NODET)</b>
  - title: Publications # Title for the section
    layout: list # Type of content section (list/text)
    content:
      - layout: left
        title: Neural Response Interpretation through the Lens of Critical Pathways
        #link: https://arxiv.org/abs/2103.16886
        #link_text: arXiv 
        image: /images/pathway.jpg
        additional_links:
          - title:  Pathway-Grad Code
            icon: fab fa-github
            url: https://github.com/CAMP-eXplain-AI/PathwayGrad
          - title:  ROAR-PyTorch Code
            icon: fab fa-github
            url: https://github.com/CAMP-eXplain-AI/RoarTorch
        #quote: >
        #  Short overview of the project (optional)
        description: | # this will include new lines to allow paragraphs
          Is critical input information encoded in specific sparse pathways within the neural network? In this work, we discuss the problem of identifying these critical pathways and subsequently 
          leverage them for interpreting the network's response to an input. The pruning objective -- selecting the smallest group of neurons for which the response remains equivalent to the 
          original network -- has been previously proposed for identifying critical pathways. We demonstrate that sparse pathways derived from pruning do not necessarily encode critical input information. 
          To ensure sparse pathways include critical fragments of the encoded input information, we propose pathway selection via neurons' contribution to the response. We proceed to explain how critical pathways can 
          reveal critical input features. We prove <span id="dots_1">...</span><span id="more_1" style="display:none"> that pathways selected via neuron contribution are locally linear (in an L2-ball), a property that we use for 
          proposing a feature attribution method: "pathway gradient". We validate our interpretation method using mainstream evaluation experiments. The validation of pathway gradient interpretation method further confirms 
          that selected pathways using neuron contributions correspond to critical input features.
          
          <button onclick="moreFunction("dots_1", "more_1", "moreBtn_1")" id="moreBtn_1" style:"background-color: #808080; border: none; color: white; text-align: center; text-decoration: none; display: inline-block;">More</button>
          
          <span style="color:#006400"> Ashkan Khakzar, <strong>Soroosh Baselizadeh</strong>, Saurabh Khanduja, Christian Rupprecht, Seong Tae Kim, and Nassir Navab </span>
          
          <span style="color:#000099"> IEEE/CVF Conference on Computer Vision and Pattern Recognition (<mark>CVPR</mark>) 2021
          [<a href="https://arxiv.org/abs/2103.16886">arXiv</a>][<a href="https://openaccess.thecvf.com/content/CVPR2021/html/Khakzar_Neural_Response_Interpretation_Through_the_Lens_of_Critical_Pathways_CVPR_2021_paper.html">CVF Open Access (CVPR2021)</a>]</span>
      - layout: left 
        title: Multiresolution Knowledge Distillation for Anomaly Detection
        image: /images/ad_kd.jpg
        additional_links:
          - title:  AD_KD Code
            icon: fab fa-github
            url: https://github.com/rohban-lab/Knowledge_Distillation_AD
        #quote: >
        #  Short overview of the project (optional)
        description: | # this will include new lines to allow paragraphs
          Unsupervised representation learning has proved to be a critical component of anomaly detection/localization in images. 
          The challenges to learn such a representation are two-fold. Firstly, the sample size is not often large enough to learn a rich generalizable representation through 
          conventional techniques. Secondly, while only normal samples are available at training, the learned features should be discriminative of normal and anomalous samples. 
          Here, we propose to use the “distillation” of features at various layers of an expert network, which is pre-trained on ImageNet, into a simpler cloner network to tackle both issues. 
          We detect and localize anomalies <span id="dots_2">...</span><span id="more_2" style="display:none"> using the discrepancy between the expert and cloner networks’ intermediate activation values given an input sample. 
          We show that considering multiple intermediate hints in distillation leads to better exploitation of the expert’s knowledge and a more distinctive discrepancy between the two networks, 
          compared to utilizing only the last layer activation values. Notably, previous methods either fail in precise anomaly localization or need expensive region-based training. In contrast, 
          with no need for any special or intensive training procedure, we incorporate interpretability algorithms in our novel framework to localize anomalous regions. 
          Despite the striking difference between some test datasets and ImageNet, we achieve competitive or significantly superior results compared to SOTA on MNIST, F-MNIST, CIFAR-10, MVTecAD, Retinal-OCT, 
          and two other medical datasets on both anomaly detection and localization.</span>
          <button onclick="moreFunction("dots_2", "more_2", "moreBtn_2")" id="moreBtn_2" style:"background-color: #808080; border: none; color: white; text-align: center; text-decoration: none; display: inline-block;">More</button>
          
          <span style="color:#006400"> MohammadReza Salehi, Niousha Sadjadi*, <strong>Soroosh Baselizadeh*</strong>, Mohammad Hossein Rohban, and Hamid R. Rabiee </span>
          
          <span style="color:#000099"> IEEE/CVF Conference on Computer Vision and Pattern Recognition (<mark>CVPR</mark>) 2021
          [<a href="https://arxiv.org/abs/2011.11108">arXiv</a>][<a href="https://openaccess.thecvf.com/content/CVPR2021/html/Salehi_Multiresolution_Knowledge_Distillation_for_Anomaly_Detection_CVPR_2021_paper.html">CVF Open Access (CVPR2021)</a>]</span>
      
      - layout: left 
        title: Towards Semantic Interpretation of Thoracic Disease and COVID-19 Diagnosis Models
        additional_links:
          - title:  Covid_Interpretation Code
            icon: fab fa-github
            url: https://github.com/CAMP-eXplain-AI/CheXplain-Dissection
        image: /images/covid.jpg 
        description: |
          Convolutional neural networks are showing promise in the automatic diagnosis of thoracic pathologies on chest x-rays. Their black-box nature has sparked many recent works to explain the prediction via 
          input feature attribution methods (aka saliency methods). However, input feature attribution methods merely identify the importance of input regions for the prediction and lack semantic interpretation 
          of model behavior. In this work, we first identify the semantics associated with internal units (feature maps) of the network. We proceed to investigate the following questions; Does a regression model 
          that is only trained with COVID-19 severity scores implicitly learn visual patterns associated with thoracic pathologies? Does a network that is trained on weakly labeled data (e.g. healthy, unhealthy) 
          implicitly learn pathologies? Moreover, <span id="dots_3">...</span><span id="more_3" style="display:none"> we investigate the effect of pretraining and data imbalance on the interpretability of learned features. 
          In addition to the analysis, we propose semantic attribution to semantically explain each prediction. We present our findings using publicly available chest pathologies (CheXpert, NIH ChestX-ray8) 
          and COVID-19 datasets (BrixIA, and COVID-19 chest X-ray segmentation dataset).
          <button onclick="moreFunction("dots_3", "more_3", "moreBtn_3")" id="moreBtn_3" style:"background-color: #808080; border: none; color: white; text-align: center; text-decoration: none; display: inline-block;">More</button>
                    
          <span style="color:#006400"> Ashkan Khakzar, Sabrina Musatian, Jonas Buchberger, Icxel Valeriano Quiroz, Nikolaus Pinger, <strong>Soroosh Baselizadeh</strong>, Seong Tae Kim, Nassir Navab </span>
          <span style="color:#000099"> International Conference on Medical Image Computing and Computer-Assisted Intervention (<mark>MICCAI</mark>) 2021
          [<a href="https://arxiv.org/abs/2104.02481">arXiv</a>]
          [<a href="https://link.springer.com/chapter/10.1007%2F978-3-030-87199-4_47">Springer (DOI)</a>]
          [<a href="https://rdcu.be/cyl4H">SharedIt</a>]</span>         
      
      - layout: left 
        title: Rethinking Positive Aggregation and Propagation of Gradients in Gradient-based Saliency Methods
        image: /images/rethink.jpg
        #quote: >
        #  Short overview of the project (optional)
        description: | # this will include new lines to allow paragraphs
          Saliency methods interpret the prediction of a neural network by showing the importance of input elements for that prediction. A popular family of saliency methods utilize gradient information. 
          In this work, we empirically show that two approaches for handling the gradient information, namely positive aggregation, and positive propagation, break these methods. Though these methods reflect 
          visually salient information in the input, they do not explain the model prediction anymore as the generated saliency maps are insensitive to the predicted output and are insensitive to model parameter 
          randomization. Specifically for methods that aggregate the gradients of a chosen layer such as GradCAM++ and FullGrad, exclusively aggregating positive gradients is detrimental. 
          <span id="dots_4">...</span><span id="more_4" style="display:none"> We further support this by proposing several variants of aggregation methods with positive handling of gradient information. 
          For methods that backpropagate gradient information such as LRP, RectGrad, and Guided Backpropagation, we show the destructive effect of exclusively propagating positive gradient information.
          <button onclick="moreFunction("dots_4", "more_4", "moreBtn_4")" id="moreBtn_4" style:"background-color: #808080; border: none; color: white; text-align: center; text-decoration: none; display: inline-block;">More</button>
          
          <span style="color:#006400"> Ashkan Khakzar, <strong>Soroosh Baselizadeh</strong> and Nassir Navab </span>
          
          <span style="color:#000099"> International Conference on Machine Learning (<mark>ICML</mark>) 2020 - Workshop on Human Interpretability in ML (<mark>WHI</mark>)
          [<a href="https://arxiv.org/abs/2012.00362">arXiv</a>][<a href="https://drive.google.com/file/d/1lKd1bciGkeh1y6fjwJlUpToD1eJyzap5/view?usp=sharing">Full Proceedings of the Venue</a>]</span>
          
          
      #- layout: left 
      #  title: Improving Feature Attribution through Input-specific Network Pruning
      #  image: /images/pruning.jpg 
      #  description: |
      #    Attributing the output of a neural network to the contribution of given input elements is a way of shedding light on the black-box nature of neural networks. Due to the complexity of current network architectures, current gradient-based attribution methods provide very noisy or coarse results. We propose to prune a neural network for a given single input to keep only neurons that highly contribute to the prediction. We show that by input-specific pruning, network gradients change from reflecting local (noisy) importance information to global importance. Our proposed method is efficient and generates fine-grained attribution maps. We further provide a theoretical justification of the pruning approach relating it to perturbations and validate it through a novel experimental setup. Our method is evaluated by multiple benchmarks: sanity checks, pixel perturbation, and Remove-and-Retrain (ROAR). These benchmarks evaluate the method from different perspectives and our method performs better than other methods across all evaluations.
          
      #    <span style="color:#006400"> Ashkan Khakar, <strong>Soroosh Baselizadeh</strong>, Saurabh Khanduja, Christian Rupprecht, Seong Tae Kim, and Nassir Navab </span>
      #    <span style="color:#000099">[<a href="https://arxiv.org/abs/1911.11081">arXiv</a>]</span>
  - title: Experience
    layout: list
    content:
      - layout: left
        title: Technical University of Munich, Germany
        sub_title: Research Intern - Remote Research Assistant
        caption: July 2019 - Sep. 2019 / Sep. 2019 - March 2021
        link: http://campar.in.tum.de/
        quote: >
          Undergraduate Excellence Award from the Chair for Computer Aided Medical Procedueres and Augmented Reality (CAMP) @ TUM
        description: | # this will include new lines to allow paragraphs
          Under the supervision of <a href="https://scholar.google.de/citations?user=kzoVUPYAAAAJ&hl=en"><mark>Prof. Nassir Navab</mark></a>.
          Working on explainable ML, the interpretability of neural networks, critical data routing paths within deep models, and network pruning.
      - layout: left
        title: Robust and Interpretable Machine Learning (RIML) Lab
        sub_title: Research Assistant
        caption: March 2019 - March. 2021
        quote: >
          @ Sharif University of Technology, Tehran, Iran
        description: | # this will include new lines to allow paragraphs
          Under the supervision of <a href="https://scholar.google.com/citations?hl=en&user=pRyJ6FkAAAAJ"><mark>Prof. Mohammad Hossein Rohban</mark></a>.
          Working on machine learning and computer vision with a focus on anomaly detection, transfer learning, knowledge distillation, adversarial robustness, and meta-learning.
      - layout: left
        title: Asr-Gooyesh Pardaz Company
        sub_title: Intern
        caption: Sep. 2021 - Jan. 2021
        link: http://asr-gooyesh.com/en/
        additional_links:
          - title:  Asr-Gooyesh Pardaz LinkedIn
            icon: fab fa-linkedin
            url: https://www.linkedin.com/company/asr-gooyesh-pardaz-co-/
        quote: >
          Tehran, Iran
        description: | # this will include new lines to allow paragraphs
          Working on a real-world project for ML-based detection of offensive comments in Persian websites. Gathered
          valuable real-world data from Persian news websites and processed them. Then, used the created dataset to design and test different approaches
          (e.g self-training, BERT, ...) for the best results.
  - title: Honors & Awards
    layout: text
    content: | # this will include new lines to allow paragraphs
      - David R. Cheriton Scholarship Graduate Scholarship, Department of Computer Science, University of Waterloo [2021-2023]
    
      - International Master's Award of Excellence (IMAE), University of Waterloo [2021-2023]
    
      - Undergraduate Excellence Award from the Technical University of Munich, Germany [2019]: given annually
        to <= 5 international students with an excellent background by the chair for Computer Aided Medical Procedures and Augmented Reality (CAMP). 
        
      - Ranked 3rd based on GPA out of all ~110 bachelor students of Computer Enigneering Department @ Sharif University of Technology entered at 2016. 
      
      - Iran's National Elites Foundation (INEF) Fellowship [2016-2021]: Recognized as scientiffic elite.

      - Iran's National University Entrance Exam (Konkur) Top Scorer [2016]: Ranked 12th nationally (2nd in the relevant region) out of more than 180'000 (50'000 in the relevant region) participants.
      


# Footer
footer_show_references: true
# references_title: References on request (Override references text)

# Build settings
# theme: modern-resume-theme (Use this is you are hosting your resume yourself)
# remote_theme: sproogen/modern-resume-theme (Use this if you are hosting your resume on GitHub)

sass:
  sass_dir: _sass
  style: compressed

plugins:
 - jekyll-seo-tag

exclude : [
  "Gemfile",
  "Gemfile.lock",
  "node_modules",
  "vendor/bundle/",
  "vendor/cache/",
  "vendor/gems/",
  "vendor/ruby/",
  "lib/",
  "scripts/",
  "docker-compose.yml",
  ]
