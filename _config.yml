# Site
repository: https://github.com/Soroosh-Bsl/soroosh-bsl.github.io
# favicon: Directory of your favicon (eg. images/favicon.ico)(optional)

# Content configuration version
version: 2

# Personal info
name: Soroosh Baselizadeh
# title: Your job title
email: soroosh.baselizadeh@gmail.com
# email_title: Email (Email title override)
# phone: Your phone number (optional)
# phone_title: Phone (Phone title override)
# website: Your website (eg. https://google.com)(optional)
# website_title: Web (Website title override)

# Dark Mode (true/false/never)
darkmode: false

# Social links
# twitter_username: jekyllrb
github_username:  soroosh-bsl
#stackoverflow_username: "00000001"
#dribbble_username: jekyll
#facebook_username: jekyll
#flickr_username: jekyll
#instagram_username: jekyll
linkedin_username: soroosh-baselizadeh-68591019b
#xing_username: jekyll
#pinterest_username: jekyll
#youtube_username: jekyll
#googleplus_username: +jekyll
#orcid_username: 0000-0000-0000-0000
semantic_scholar_username: Soroosh-Baselizadeh/1429835055
# google_scholar_username: ---

# Additional icon links
#additional_links:
# - title: My SemanticScholar
#  icon: ai ai-semantic-scholar ai-4x
#  url: https://www.semanticscholar.org/author/Soroosh-Baselizadeh/1429835055
# - title: another link
#   icon: font awesome brand icon name (eg. fab fa-twitter) (https://fontawesome.com/icons?d=gallery&s=brands&m=free)
#   url: Link url (eg. https://google.com)

# Google Analytics and Tag Manager
# Using more than one of these may cause issues with reporting
# gtm: "GTM-0000000"
# gtag: "UA-00000000-0"
# google_analytics: "UA-00000000-0"
#<a href='https://www.freepik.com/vectors/background'>Background vector created by freepik - www.freepik.com</a>
# About Section
# about_title: About Me (Use this to override about section title)
about_profile_image: /images/profile.jpg
about_content: | # this will include new lines to allow paragraphs
  Write an awesome description about yourself here, this supports markdown, so you can add [links](http://foobar.com) and highlight things <mark>like this</mark>.
  
  You can even add paragraphs by using empty lines like this and add anything else [markdown](https://www.markdownguide.org/getting-started#what-is-markdown) supports such as
    - Lists
    - Tables
    - <a href="google.com">Links</a>

content:
  - title: Education
    layout: list
    content:
      - layout: top-left
        title: Sharif University of Technology
        sub_title: BSc in Computer Engineeiring
        caption: Sep. 2016 - Feb. 2021
        quote: >
          <span style="color=#000099">Ranked 3rd/~110, GPA: 19.45/20</span>
        description: | # this will include new lines to allow paragraphs          
          Related Coursework: Probability & Statistics, Linear Algebra, Artificial Intelligence, Signals & Systems,
          Modern Information Retrieval, Algorithmic Game Theory, Numerical Methods, Design of Algorithms,
          Computer Simulation, Database Design, Data Structures & Algorithms
      - layout: top-left
        title: Allameh-Helli 1 High School
        sub_title: Diploma in Mathematics and Physics
        caption: 2012 - 2016
        quote: >
          <span style="color=#000099">Ranked 1st, GPA: 19.88/20</span>
        description: | # this will include new lines to allow paragraphs          
          Affiliated with the National Organization of Exceptional Talents (NODET)
  - title: Publications # Title for the section
    layout: list # Type of content section (list/text)
    content:
      - layout: left
        title: Neural Response Interpretation through the Lens of Critical Pathways
        #link: https://arxiv.org/abs/2103.16886
        #link_text: arXiv 
        image: /images/pathway.jpg
        additional_links:
          - title:  Pathway-Grad Code
            icon: fab fa-github
            url: https://github.com/CAMP-eXplain-AI/PathwayGrad
          - title:  ROAR-PyTorch Code
            icon: fab fa-github
            url: https://github.com/CAMP-eXplain-AI/RoarTorch
        #quote: >
        #  Short overview of the project (optional)
        description: | # this will include new lines to allow paragraphs
          Is critical input information encoded in specific sparse pathways within the neural network? In this work, we discuss the problem of identifying these critical pathways and subsequently leverage them for interpreting the network's response to an input. The pruning objective -- selecting the smallest group of neurons for which the response remains equivalent to the original network -- has been previously proposed for identifying critical pathways. We demonstrate that sparse pathways derived from pruning do not necessarily encode critical input information. To ensure sparse pathways include critical fragments of the encoded input information, we propose pathway selection via neurons' contribution to the response. We proceed to explain how critical pathways can reveal critical input features. We prove that pathways selected via neuron contribution are locally linear (in an L2-ball), a property that we use for proposing a feature attribution method: "pathway gradient". We validate our interpretation method using mainstream evaluation experiments. The validation of pathway gradient interpretation method further confirms that selected pathways using neuron contributions correspond to critical input features.
          
          <span style="color:#006400"> Ashkan Khakar, <strong>Soroosh Baselizadeh</strong>, Saurabh Khanduja, Christian Rupprecht, Seong Tae Kim, and Nassir Navab </span>
          
          <span style="color:#000099"> IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>) 2021
          [<a href="url(/files/pathwaygrad_main.pdf)">PDF</a>][<a href="url(/files/pathwaygrad_appendix.pdf)">Appendix</a>][<a href="https://arxiv.org/abs/2103.16886">arXiv</a>]</span>
      - layout: left 
        title: Multiresolution Knowledge Distillation for Anomaly Detection
        image: /images/ad_kd.jpg
        additional_links:
          - title:  AD_KD Code
            icon: fab fa-github
            url: https://github.com/rohban-lab/Knowledge_Distillation_AD
        #quote: >
        #  Short overview of the project (optional)
        description: | # this will include new lines to allow paragraphs
          Unsupervised representation learning has proved to be a critical component of anomaly detection/localization in images. The challenges to learn such a representation are two-fold. Firstly, the sample size is not often large enough to learn a rich generalizable representation through conventional techniques. Secondly, while only normal samples are available at training, the learned features should be discriminative of normal and anomalous samples. Here, we propose to use the "distillation" of features at various layers of an expert network, pre-trained on ImageNet, into a simpler cloner network to tackle both issues. We detect and localize anomalies using the discrepancy between the expert and cloner networks' intermediate activation values given the input data. We show that considering multiple intermediate hints in distillation leads to better exploiting the expert's knowledge and more distinctive discrepancy compared to solely utilizing the last layer activation values. Notably, previous methods either fail in precise anomaly localization or need expensive region-based training. In contrast, with no need for any special or intensive training procedure, we incorporate interpretability algorithms in our novel framework for the localization of anomalous regions.
          
          <span style="color:#006400"> MohammadReza Salehi, Niousha Sadjadi*, <strong>Soroosh Baselizadeh*</strong>, Mohammad Hossein Rohban, and Hamid R. Rabiee </span>
          
          <span style="color:#000099"> IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>) 2021
          [<a href="url(/pubs/ad_kd_main.pdf)">PDF</a>][<a href="url(/pubs/ad_kd_appendix.pdf)">Appendix</a>][<a href="https://arxiv.org/abs/2011.11108">arXiv</a>]</span>
      
      - layout: left 
        title: Rethinking Positive Aggregation and Propagation of Gradients in Gradient-based Saliency Methods
        image: /images/rethink.jpg
        #quote: >
        #  Short overview of the project (optional)
        description: | # this will include new lines to allow paragraphs
          Saliency methods interpret the prediction of a neural network by showing the importance of input elements for that prediction. A popular family of saliency methods utilize gradient information. In this work, we empirically show that two approaches for handling the gradient information, namely positive aggregation, and positive propagation, break these methods. Though these methods reflect visually salient information in the input, they do not explain the model prediction anymore as the generated saliency maps are insensitive to the predicted output and are insensitive to model parameter randomization. Specifically for methods that aggregate the gradients of a chosen layer such as GradCAM++ and FullGrad, exclusively aggregating positive gradients is detrimental. We further support this by proposing several variants of aggregation methods with positive handling of gradient information. For methods that backpropagate gradient information such as LRP, RectGrad, and Guided Backpropagation, we show the destructive effect of exclusively propagating positive gradient information.
          
          <span style="color:#006400"> Ashkan Khakzar, <strong>Soroosh Baselizadeh</strong> and Nassir Navab </span>
          
          <span style="color:#000099"> International Conference on Machine Learning (<strong>ICML</strong>) 2020 - Workshop on Human Interpretability in ML (<strong>WHI</strong>)
          [<a href="url(/pubs/rethink_pos_grad_main.pdf)">PDF</a>][<a href="https://arxiv.org/abs/2012.00362">arXiv</a>][<a href="url(/pubs/rethink_pos_grad_vid.pdf)">Presentation</a>]</span>
      - layout: left 
        title: Towards Semantic Interpretation of Thoracic Disease and COVID-19 Diagnosis Models
        additional_links:
          - title:  Covid_Interpretation Code
            icon: fab fa-github
            url: https://github.com/CAMP-eXplain-AI/CheXplain-Dissection
        image: /images/covid.jpg 
        description: |
          Convolutional neural networks are showing promise in the automatic diagnosis of thoracic pathologies on chest x-rays. Their black-box nature has sparked many recent works to explain the prediction via input feature attribution methods (aka saliency methods). However, input feature attribution methods merely identify the importance of input regions for the prediction and lack semantic interpretation of model behavior. In this work, we first identify the semantics associated with internal units (feature maps) of the network. We proceed to investigate the following questions; Does a regression model that is only trained with COVID-19 severity scores implicitly learn visual patterns associated with thoracic pathologies? Does a network that is trained on weakly labeled data (e.g. healthy, unhealthy) implicitly learn pathologies? Moreover, we investigate the effect of pretraining and data imbalance on the interpretability of learned features. In addition to the analysis, we propose semantic attribution to semantically explain each prediction. We present our findings using publicly available chest pathologies (CheXpert, NIH ChestX-ray8) and COVID-19 datasets (BrixIA, and COVID-19 chest X-ray segmentation dataset).
          
          <span style="color:#006400"> Ashkan Khakzar, Sabrina Musatian, Jonas Buchberger, Icxel Valeriano Quiroz, Nikolaus Pinger, <strong>Soroosh Baselizadeh</strong>, Seong Tae Kim, Nassir Navab </span>
          <span style="color:#000099">[<a href="https://arxiv.org/abs/2104.02481">arXiv</a>]</span>
          
      - layout: left 
        title: Improving Feature Attribution through Input-specific Network Pruning
        image: /images/pruning.jpg 
        description: |
          Attributing the output of a neural network to the contribution of given input elements is a way of shedding light on the black-box nature of neural networks. Due to the complexity of current network architectures, current gradient-based attribution methods provide very noisy or coarse results. We propose to prune a neural network for a given single input to keep only neurons that highly contribute to the prediction. We show that by input-specific pruning, network gradients change from reflecting local (noisy) importance information to global importance. Our proposed method is efficient and generates fine-grained attribution maps. We further provide a theoretical justification of the pruning approach relating it to perturbations and validate it through a novel experimental setup. Our method is evaluated by multiple benchmarks: sanity checks, pixel perturbation, and Remove-and-Retrain (ROAR). These benchmarks evaluate the method from different perspectives and our method performs better than other methods across all evaluations.
          
          <span style="color:#006400"> Ashkan Khakar, <mark>Soroosh Baselizadeh</mark>, Saurabh Khanduja, Christian Rupprecht, Seong Tae Kim, and Nassir Navab </span>
          <span style="color:#000099">[<a href="https://arxiv.org/abs/1911.11081">arXiv</a>]</span>
  - title: Experience
    layout: list
    content:
      - layout: left
        title: Technical University of Munich, Germany
        sub_title: Research Intern - Remote Research Assistant
        caption: July 2019 - Sep. 2019 / Sep. 2019 - March 2021
        link: http://campar.in.tum.de/
        quote: >
          Chair for Computer Aided Medical Procedueres and Augmented Reality (CAMP) @ TUM
        description: | # this will include new lines to allow paragraphs
          Under the supervision of <a href="https://scholar.google.de/citations?user=kzoVUPYAAAAJ&hl=en"><mark>Prof. Nassir Navab</mark></a>
  - title: A Little More About Me
    layout: text
    content: | # this will include new lines to allow paragraphs
      This is where you can write a little more about yourself. You could title this section **Interests** and include some of your other interests.

      Or you could title it **Skills** and write a bit more about things that make you more desirable, like *leadership* or *teamwork*

# Footer
footer_show_references: true
# references_title: References on request (Override references text)

# Build settings
# theme: modern-resume-theme (Use this is you are hosting your resume yourself)
# remote_theme: sproogen/modern-resume-theme (Use this if you are hosting your resume on GitHub)

sass:
  sass_dir: _sass
  style: compressed

plugins:
 - jekyll-seo-tag

exclude : [
  "Gemfile",
  "Gemfile.lock",
  "node_modules",
  "vendor/bundle/",
  "vendor/cache/",
  "vendor/gems/",
  "vendor/ruby/",
  "lib/",
  "scripts/",
  "docker-compose.yml",
  ]
