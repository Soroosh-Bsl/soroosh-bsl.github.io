# Site
repository: https://github.com/Soroosh-Bsl/soroosh-bsl.github.io
# favicon: Directory of your favicon (eg. images/favicon.ico)(optional)

# Content configuration version
version: 2

# Personal info
name: Soroosh Baselizadeh
# title: Your job title
email: soroosh.baselizadeh@gmail.com
# email_title: Email (Email title override)
# phone: Your phone number (optional)
# phone_title: Phone (Phone title override)
# website: Your website (eg. https://google.com)(optional)
# website_title: Web (Website title override)

# Dark Mode (true/false/never)
darkmode: false

# Social links
# twitter_username: jekyllrb
github_username:  soroosh-bsl
#stackoverflow_username: "00000001"
#dribbble_username: jekyll
#facebook_username: jekyll
#flickr_username: jekyll
#instagram_username: jekyll
linkedin_username: soroosh-baselizadeh
#xing_username: jekyll
#pinterest_username: jekyll
#youtube_username: jekyll
#googleplus_username: +jekyll
#orcid_username: 0000-0000-0000-0000
semantic_scholar_username: Soroosh-Baselizadeh+1429835055
google_scholar_username: DHb2F-0AAAAJ

# Additional icon links
#additional_links:
# - title: My SemanticScholar
#  icon: ai ai-semantic-scholar ai-4x
#  url: https://www.semanticscholar.org/author/Soroosh-Baselizadeh/1429835055
# - title: another link
#   icon: font awesome brand icon name (eg. fab fa-twitter) (https://fontawesome.com/icons?d=gallery&s=brands&m=free)
#   url: Link url (eg. https://google.com)

# Google Analytics and Tag Manager
# Using more than one of these may cause issues with reporting
# gtm: "GTM-0000000"
# gtag: "UA-00000000-0"
# google_analytics: "UA-00000000-0"
#<a href='https://www.freepik.com/vectors/background'>Background vector created by freepik - www.freepik.com</a>
# About Section
# about_title: About Me (Use this to override about section title)
about_profile_image: /images/profile.jpg
about_content: | # this will include new lines to allow paragraphs
  I am a Computer Vision, Machine Learning and Deep Learning graduate researcher currently at the University of Waterloo, 
  where I am supervised by <a href="https://scholar.google.com/citations?hl=en&user=h6_PdYsAAAAJ">Prof. Yuri Boykov</a> and 
  <a href="https://scholar.google.com/citations?hl=en&user=r5QkMysAAAAJ">Prof. Olga Veksler</a>. My focus at the moment is around learning better instance/semantic segmentation via learning edges. In past, I have been a research assistant at Computer Aided Medical Procedures (<a href="https://www.cs.cit.tum.de/camp/start/">CAMP</a>) @ Technical University of Munich (supervised by <a href="https://scholar.google.de/citations?hl=en&user=kzoVUPYAAAAJ&view_op=list_works&sortby=pubdate">Prof. Nassir Navab</a>), where we published several wonderfully interesting projects at CVPR, MICCAI, and ICML on explainable ML, and interpretability in medical applications of deep learning. Besides, I have worked as a member of Robust and Interpretable ML Lab @ Sharif University of Technology, Iran (supervised by <a href="https://scholar.google.com/citations?hl=en&user=pRyJ6FkAAAAJ&view_op=list_works&sortby=pubdate">Prof. MH Rohban</a>), where I worked on an interesting project for anomaly detection/localization in which we improved the tate-of-the-art by a margin on 7 datasets through a novel teacher-student knowledge distillation and transfer learning setting. 

content:
  - title: Education
    layout: list
    content:
      - layout: left
        title: University of Waterloo
        sub_title: Master's in Computer Science
        caption: Sep. 2021 - Present
        description: |
            <b>Supervisors</b>: <a href="https://scholar.google.com/citations?hl=en&user=h6_PdYsAAAAJ&view_op=list_works&sortby=pubdate">Prof. Yuri Boykov</a> 
            and <a href="https://scholar.google.com/citations?hl=en&user=r5QkMysAAAAJ&view_op=list_works&sortby=pubdate">Prof. Olga Veksler</a>
            <br><b>Related Coursework</b>: Deep Learning, Computational Vision, Reinforcement Learning
      - layout: left
        title: Sharif University of Technology
        sub_title: BSc in Computer Engineeiring
        caption: Sep. 2016 - Feb. 2021
        quote: >
          <mark>Ranked 3rd/~110, GPA: 19.45/20</mark>
        description: | # this will include new lines to allow paragraphs          
          <b>Supervisor</b>: <a href="https://scholar.google.com/citations?hl=en&user=pRyJ6FkAAAAJ&view_op=list_works&sortby=pubdate">Prof. MH Rohban</a>
          <br><b>Related Coursework</b>: Probability & Statistics, Linear Algebra, Artificial Intelligence, Signals & Systems, Modern Information Retrieval, Algorithmic Game Theory, Numerical Methods, Design of Algorithms, Computer Simulation, Database Design, Data Structures & Algorithms
  - title: Publications # Title for the section
    layout: list # Type of content section (list/text)
    content:
      - layout: top
        title: Neural Response Interpretation through the Lens of Critical Pathways
        #link: https://arxiv.org/abs/2103.16886
        #link_text: arXiv 
        image: /images/pathway.jpg
        additional_links:
          - title:  Pathway-Grad Code
            icon: fab fa-github
            url: https://github.com/CAMP-eXplain-AI/PathwayGrad
          - title:  ROAR-PyTorch Code
            icon: fab fa-github
            url: https://github.com/CAMP-eXplain-AI/RoarTorch
        #quote: >
        #  Short overview of the project (optional)
        description: | # this will include new lines to allow paragraphs
          Is critical input information encoded in specific sparse pathways within the neural network? In this work, we discuss the problem of identifying these critical pathways and subsequently 
          leverage them for interpreting the network's response to an input. We demonstrate that sparse pathways derived from pruning do not necessarily encode critical input information. <span id="dots_1">...</span><span id="more_1" style="display:none">The pruning objective -- selecting the smallest group of neurons for which the response remains equivalent to the 
          original network -- has been previously proposed for identifying critical pathways. As stated, using pruning objective is flawed for obtaining pathways encoding critical input information.
          To ensure sparse pathways include critical fragments of the encoded input information, we propose pathway selection via neurons' contribution to the response. We proceed to explain how critical pathways can 
          reveal critical input features. We prove that pathways selected via neuron contribution are locally linear (in an L2-ball), a property that we use for 
          proposing a feature attribution method: "pathway gradient". We validate our interpretation method using mainstream evaluation experiments. The validation of pathway gradient interpretation method further confirms 
          that selected pathways using neuron contributions correspond to critical input features.</span>
          <button onclick="moreFunction('dots_1', 'more_1', 'moreBtn_1')" id="moreBtn_1" style="background-color: transparent; border: none; color: black; text-align: center; text-decoration: none; display: inline-block;"><strong>More</strong></button>
          
          <span style="color:#006400"> Ashkan Khakzar, <strong>Soroosh Baselizadeh</strong>, Saurabh Khanduja, Christian Rupprecht, Seong Tae Kim, and Nassir Navab </span>
          
          <span style="color:#000099"> IEEE/CVF Conference on Computer Vision and Pattern Recognition (<mark>CVPR</mark>) 2021
          [<a href="https://arxiv.org/abs/2103.16886">arXiv</a>][<a href="https://openaccess.thecvf.com/content/CVPR2021/html/Khakzar_Neural_Response_Interpretation_Through_the_Lens_of_Critical_Pathways_CVPR_2021_paper.html">CVF OpenAccess</a>]</span>
      - layout: top 
        title: Multiresolution Knowledge Distillation for Anomaly Detection
        image: /images/ad_kd.jpg
        additional_links:
          - title:  AD_KD Code
            icon: fab fa-github
            url: https://github.com/rohban-lab/Knowledge_Distillation_AD
        #quote: >
        #  Short overview of the project (optional)
        description: | # this will include new lines to allow paragraphs
          Here, we propose to use the “distillation” of features at various layers of an expert network, which is pre-trained on ImageNet, into a simpler cloner network to tackle issues in
          unsupervised representation learning for anomaly detection/localization. 
          We detect and localize anomalies using the discrepancy between the expert and cloner networks’ intermediate activation values given an input sample. <span id="dots_2">...</span><span id="more_2" style="display:none">
          Unsupervised representation learning has proved to be a critical component of anomaly detection/localization in images. 
          The challenges to learn such a representation are two-fold. Firstly, the sample size is not often large enough to learn a rich generalizable representation through 
          conventional techniques. Secondly, while only normal samples are available at training, the learned features should be discriminative of normal and anomalous samples. 
          Here, we propose to use the “distillation” of features at various layers of an expert network, which is pre-trained on ImageNet, into a simpler cloner network to tackle both issues. 
          We detect and localize anomalies using the discrepancy between the expert and cloner networks’ intermediate activation values given an input sample. 
          We show that considering multiple intermediate hints in distillation leads to better exploitation of the expert’s knowledge and a more distinctive discrepancy between the two networks, 
          compared to utilizing only the last layer activation values. Notably, previous methods either fail in precise anomaly localization or need expensive region-based training. In contrast, 
          with no need for any special or intensive training procedure, we incorporate interpretability algorithms in our novel framework to localize anomalous regions. 
          Despite the striking difference between some test datasets and ImageNet, we achieve competitive or significantly superior results compared to SOTA on MNIST, F-MNIST, CIFAR-10, MVTecAD, Retinal-OCT, 
          and two other medical datasets on both anomaly detection and localization.</span> 
          <button onclick="moreFunction('dots_2', 'more_2', 'moreBtn_2')" id="moreBtn_2" style="background-color: transparent; border: none; color: black; text-align: center; text-decoration: none; display: inline-block;"><strong>More</strong></button>
          
          <span style="color:#006400"> MohammadReza Salehi, Niousha Sadjadi*, <strong>Soroosh Baselizadeh*</strong>, M. H. Rohban, and Hamid R. Rabiee </span>
          
          <span style="color:#000099"> IEEE/CVF Conference on Computer Vision and Pattern Recognition (<mark>CVPR</mark>) 2021
          [<a href="https://arxiv.org/abs/2011.11108">arXiv</a>][<a href="https://openaccess.thecvf.com/content/CVPR2021/html/Salehi_Multiresolution_Knowledge_Distillation_for_Anomaly_Detection_CVPR_2021_paper.html">CVF OpenAccess</a>]</span>
      
      - layout: top 
        title: Towards Semantic Interpretation of Thoracic Disease and COVID-19 Diagnosis Models
        additional_links:
          - title:  Covid_Interpretation Code
            icon: fab fa-github
            url: https://github.com/CAMP-eXplain-AI/CheXplain-Dissection
        image: /images/covid.jpg 
        description: |
          The black-box nature of CNNs has sparked many recent works to explain the prediction via 
          input feature attribution methods. However, input these methods merely identify the importance of input regions for the prediction and lack semantic interpretation 
          of model behavior. Here, we first identify the semantics associated with internal units (feature maps) of the network. We proceed to investigate the following questions; <span id="dots_3">...</span><span id="more_3" style="display:none">Does a regression model 
          that is only trained with COVID-19 severity scores implicitly learn visual patterns associated with thoracic pathologies? 
          Does a network that is trained on weakly labeled data (e.g. healthy, unhealthy) 
          implicitly learn pathologies? Moreover, we investigate the effect of pretraining and data imbalance on the interpretability of learned features. 
          In addition to the analysis, we propose semantic attribution to semantically explain each prediction. 
          We present our findings using publicly available chest pathologies (CheXpert, NIH ChestX-ray8) 
          and COVID-19 datasets (BrixIA, and COVID-19 chest X-ray segmentation dataset).</span>
          <button onclick="moreFunction('dots_3', 'more_3', 'moreBtn_3')" id="moreBtn_3" style="background-color: transparent; border: none; color: black; text-align: center; text-decoration: none; display: inline-block;"><strong>More</strong></button>
                    
          <span style="color:#006400"> A. Khakzar, S. Musatian, J. Buchberger, I. Valeriano Quiroz, N. Pinger, <strong>S. Baselizadeh</strong>, S. T. Kim, Nassir Navab </span>
          
          <span style="color:#000099"> International Conference on Medical Image Computing and Computer-Assisted Intervention (<mark>MICCAI</mark>) 2021
          [<a href="https://arxiv.org/abs/2104.02481">arXiv</a>]
          [<a href="https://link.springer.com/chapter/10.1007%2F978-3-030-87199-4_47">Springer (DOI)</a>]
          [<a href="https://rdcu.be/cyl4H">SharedIt</a>]</span>         
      
      - layout: top 
        title: Rethinking Positive Aggregation and Propagation of Gradients in Gradient-based Saliency Methods
        image: /images/rethink.jpg
        #quote: >
        #  Short overview of the project (optional)
        description: | # this will include new lines to allow paragraphs
          A popular family of saliency methods utilize gradient information. 
          In this work, we empirically show that two approaches for handling the gradient information, namely positive aggregation, and positive propagation, 
          (e.g. in methods like GradCAM++ and FullGrad)
          break these methods. Though these methods reflect visually salient information in the input, they do not explain the model prediction 
          anymore <span id="dots_4">...</span><span id="more_4" style="display:none">as the generated saliency maps are insensitive to the predicted output and are insensitive to model parameter 
          randomization. Specifically for methods that aggregate the gradients of a chosen layer such as GradCAM++ and FullGrad, exclusively aggregating positive gradients is detrimental. 
          We further support this by proposing several variants of aggregation methods with positive handling of gradient information. 
          For methods that backpropagate gradient information such as LRP, RectGrad, and Guided Backpropagation, we show the destructive effect of 
          exclusively propagating positive gradient information.</span>
          <button onclick="moreFunction('dots_4', 'more_4', 'moreBtn_4')" id="moreBtn_4" style="background-color: transparent; border: none; color: black; text-align: center; text-decoration: none; display: inline-block;"><strong>More</strong></button>
          
          <span style="color:#006400"> Ashkan Khakzar, <strong>Soroosh Baselizadeh</strong>, Nassir Navab </span>
          
          <span style="color:#000099"> International Conference on Machine Learning (<mark>ICML</mark>) 2020 - Workshop on Human Interpretability in ML (<mark>WHI</mark>)
          [<a href="https://arxiv.org/abs/2012.00362">arXiv</a>][<a href="https://drive.google.com/file/d/1lKd1bciGkeh1y6fjwJlUpToD1eJyzap5/view?usp=sharing">Full Proceedings of the Venue</a>]</span>
          
          
      #- layout: left 
      #  title: Improving Feature Attribution through Input-specific Network Pruning
      #  image: /images/pruning.jpg 
      #  description: |
      #    Attributing the output of a neural network to the contribution of given input elements is a way of shedding light on the black-box nature of neural networks. Due to the complexity of current network architectures, current gradient-based attribution methods provide very noisy or coarse results. We propose to prune a neural network for a given single input to keep only neurons that highly contribute to the prediction. We show that by input-specific pruning, network gradients change from reflecting local (noisy) importance information to global importance. Our proposed method is efficient and generates fine-grained attribution maps. We further provide a theoretical justification of the pruning approach relating it to perturbations and validate it through a novel experimental setup. Our method is evaluated by multiple benchmarks: sanity checks, pixel perturbation, and Remove-and-Retrain (ROAR). These benchmarks evaluate the method from different perspectives and our method performs better than other methods across all evaluations.
          
      #    <span style="color:#006400"> Ashkan Khakar, <strong>Soroosh Baselizadeh</strong>, Saurabh Khanduja, Christian Rupprecht, Seong Tae Kim, and Nassir Navab </span>
      #    <span style="color:#000099">[<a href="https://arxiv.org/abs/1911.11081">arXiv</a>]</span>
  - title: Experiences
    layout: list
    content:
      - layout: left
        title: Technical University of Munich, Germany
        sub_title: Research Intern - Remote Research Assistant
        caption: July 2019 - Sep. 2019 / Sep. 2019 - March 2021
        link: http://campar.in.tum.de/
        quote: >
          Undergraduate Excellence Award from the Chair for Computer Aided Medical Procedueres and Augmented Reality (CAMP) @ TUM
        description: | # this will include new lines to allow paragraphs
          Under the supervision of <a href="https://scholar.google.de/citations?user=kzoVUPYAAAAJ&hl=en"><mark>Prof. Nassir Navab</mark></a>.
          Working on explainable ML, the interpretability of neural networks, critical data routing paths within deep models, and network pruning.
      - layout: left
        title: Robust and Interpretable Machine Learning (RIML) Lab
        sub_title: Research Assistant
        caption: March 2019 - March. 2021
        quote: >
          @ Sharif University of Technology, Tehran, Iran
        description: | # this will include new lines to allow paragraphs
          Under the supervision of <a href="https://scholar.google.com/citations?hl=en&user=pRyJ6FkAAAAJ"><mark>Prof. Mohammad Hossein Rohban</mark></a>.
          Working on machine learning and computer vision with a focus on anomaly detection, transfer learning, knowledge distillation, adversarial robustness, and meta-learning.
      - layout: left
        title: Asr-Gooyesh Pardaz Company
        sub_title: Intern
        caption: Sep. 2021 - Jan. 2021
        link: http://asr-gooyesh.com/en/
        additional_links:
          - title:  Asr-Gooyesh Pardaz LinkedIn
            icon: fab fa-linkedin
            url: https://www.linkedin.com/company/asr-gooyesh-pardaz-co-/
        quote: >
          Tehran, Iran
        description: | # this will include new lines to allow paragraphs
          Working on a real-world project for ML-based detection of offensive comments in Persian websites. Gathered
          valuable real-world data from Persian news websites and processed them. Then, used the created dataset to design and test different approaches
          (e.g self-training, BERT, ...) for the best results.
  - title: Honors & Awards
    layout: text
    content: | # this will include new lines to allow paragraphs
      - David R. Cheriton Graduate Scholarship, Department of Computer Science, University of Waterloo [2021-2023]
    
      - International Master's Award of Excellence (IMAE), University of Waterloo [2021-2023]
    
      - Undergraduate Excellence Award from the Technical University of Munich, Germany [2019]: given annually
        to <= 5 international students with an excellent background by the chair for Computer Aided Medical Procedures and Augmented Reality (CAMP). 
        
      - Ranked 3rd based on GPA out of all ~110 bachelor students of Computer Enigneering Department @ Sharif University of Technology entered at 2016. 
      
      - Iran's National Elites Foundation (INEF) Fellowship [2016-2021]: Recognized as scientiffic elite.

      - Iran's National University Entrance Exam (Konkur) Top Scorer [2016]: Ranked 12th nationally (2nd in the relevant region) out of more than 180'000 (50'000 in the relevant region) participants.
      


# Footer
footer_show_references: true
# references_title: References on request (Override references text)

# Build settings
# theme: modern-resume-theme (Use this is you are hosting your resume yourself)
# remote_theme: sproogen/modern-resume-theme (Use this if you are hosting your resume on GitHub)

sass:
  sass_dir: _sass
  style: compressed

plugins:
 - jekyll-seo-tag

exclude : [
  "Gemfile",
  "Gemfile.lock",
  "node_modules",
  "vendor/bundle/",
  "vendor/cache/",
  "vendor/gems/",
  "vendor/ruby/",
  "lib/",
  "scripts/",
  "docker-compose.yml",
  ]
